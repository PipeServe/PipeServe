{
    "model": "Llama-2-13b",
    "gpu_name": "t4-pcie-16gb",
    "dtype": "w16a16e16",
    "max_chunk_size": 256,
    "slo_prefill": 2.0,
    "slo_decode": 0.8,
    "tp_size": 1,
    "pp_size": 1,
    "sp_size": 1,
    "dp_size": 1,
    "algorithm": "bucket",
    "verbose": false,
    "quiet": false
}